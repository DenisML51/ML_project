{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random \n",
    "import logging \n",
    "\n",
    "import torch \n",
    "import mlflow \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils \n",
    "import torch.nn as nn \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['USER'] = 'Denis Rusinov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data_mnist/train\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data_mnist/train\\MNIST\\raw\\train-images-idx3-ubyte.gz to data_mnist/train\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data_mnist/train\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data_mnist/train\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data_mnist/train\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data_mnist/train\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data_mnist/train\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data_mnist/train\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data_mnist/train\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data_mnist/train\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data_mnist/train\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data_mnist/test\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data_mnist/test\\MNIST\\raw\\train-images-idx3-ubyte.gz to data_mnist/test\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data_mnist/test\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data_mnist/test\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data_mnist/test\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data_mnist/test\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data_mnist/test\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data_mnist/test\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data_mnist/test\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data_mnist/test\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data_mnist/test\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from flask.cli import F\n",
    "\n",
    "\n",
    "train_mnist = torchvision.datasets.MNIST('data_mnist/train', train=True, \n",
    "                                         transform=transforms.Compose([transforms.ToTensor()]),\n",
    "                                         download=True)\n",
    "val_mnist = torchvision.datasets.MNIST('data_mnist/test', train=False, \n",
    "                                       transform=transforms.Compose([transforms.ToTensor()]),\n",
    "                                       download=True)\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_mnist,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_mnist,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNetwork(nn.Module):\n",
    "    def __init__(self, prob, n_inside):\n",
    "        super(FCNetwork, self).__init__() \n",
    "        self.fc1 = nn.Linear(784, n_inside)\n",
    "        self.fc2 = nn.Linear(n_inside, 10)\n",
    "        self.fc1_act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p = prob)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,28*28)\n",
    "        y = self.fc1(self.dropout(x))\n",
    "        y = self.fc1_act(y)\n",
    "        y = self.fc2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/16 16:06:17 INFO mlflow.tracking.fluent: Experiment with name 'PyTorch_test' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/Rusinov.DS/PycharmProjects/ML_project/dns_purchase/artefacts/980200151464093923', creation_time=1734329177469, experiment_id='980200151464093923', last_update_time=1734329177469, lifecycle_stage='active', name='PyTorch_test', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализация MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"PyTorch_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отключаем вывод ворнингов от MLflow\n",
    "mlflow_logger = logging.getLogger(\"mlflow\")\n",
    "mlflow_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "prob = 0.15\n",
    "n_inside = 50\n",
    "lr = 1e-3\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления точности\n",
    "def accuracy(y_pred, labels):\n",
    "    preds = torch.argmax(y_pred, dim=1)\n",
    "    return (preds == labels).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Началось обучение 1 эпохи\n",
      "The 1 Epoch of network learning is over:\n",
      "Train results Epoch 1: Train loss - 0.6602, Train accuracy - 0.8283\n",
      "Validation results Epoch 1: Val loss - 0.3185, Test accuracy - 0.9098\n",
      "Saving model because its better\n",
      "---\n",
      "Началось обучение 2 эпохи\n",
      "The 2 Epoch of network learning is over:\n",
      "Train results Epoch 2: Train loss - 0.3177, Train accuracy - 0.9091\n",
      "Validation results Epoch 2: Val loss - 0.2610, Test accuracy - 0.9266\n",
      "Saving model because its better\n",
      "---\n",
      "Началось обучение 3 эпохи\n",
      "The 3 Epoch of network learning is over:\n",
      "Train results Epoch 3: Train loss - 0.2723, Train accuracy - 0.9224\n",
      "Validation results Epoch 3: Val loss - 0.2274, Test accuracy - 0.9357\n",
      "Saving model because its better\n",
      "---\n",
      "Началось обучение 4 эпохи\n",
      "The 4 Epoch of network learning is over:\n",
      "Train results Epoch 4: Train loss - 0.2362, Train accuracy - 0.9324\n",
      "Validation results Epoch 4: Val loss - 0.1945, Test accuracy - 0.9444\n",
      "Saving model because its better\n",
      "---\n",
      "Началось обучение 5 эпохи\n",
      "The 5 Epoch of network learning is over:\n",
      "Train results Epoch 5: Train loss - 0.2074, Train accuracy - 0.9402\n",
      "Validation results Epoch 5: Val loss - 0.1734, Test accuracy - 0.9517\n",
      "Saving model because its better\n",
      "---\n",
      "Началось обучение 6 эпохи\n",
      "The 6 Epoch of network learning is over:\n",
      "Train results Epoch 6: Train loss - 0.1833, Train accuracy - 0.9467\n",
      "Validation results Epoch 6: Val loss - 0.1519, Test accuracy - 0.9572\n",
      "Saving model because its better\n",
      "---\n",
      "Началось обучение 7 эпохи\n",
      "The 7 Epoch of network learning is over:\n",
      "Train results Epoch 7: Train loss - 0.1645, Train accuracy - 0.9516\n",
      "Validation results Epoch 7: Val loss - 0.1384, Test accuracy - 0.9610\n",
      "Saving model because its better\n",
      "---\n",
      "Началось обучение 8 эпохи\n",
      "The 8 Epoch of network learning is over:\n",
      "Train results Epoch 8: Train loss - 0.1485, Train accuracy - 0.9569\n",
      "Validation results Epoch 8: Val loss - 0.1295, Test accuracy - 0.9631\n",
      "Saving model because its better\n",
      "---\n",
      "Началось обучение 9 эпохи\n",
      "The 9 Epoch of network learning is over:\n",
      "Train results Epoch 9: Train loss - 0.1376, Train accuracy - 0.9601\n",
      "Validation results Epoch 9: Val loss - 0.1228, Test accuracy - 0.9660\n",
      "Saving model because its better\n",
      "---\n",
      "Началось обучение 10 эпохи\n",
      "The 10 Epoch of network learning is over:\n",
      "Train results Epoch 10: Train loss - 0.1264, Train accuracy - 0.9625\n",
      "Validation results Epoch 10: Val loss - 0.1141, Test accuracy - 0.9683\n",
      "Saving model because its better\n",
      "---\n",
      "Началось обучение 11 эпохи\n",
      "The 11 Epoch of network learning is over:\n",
      "Train results Epoch 11: Train loss - 0.1197, Train accuracy - 0.9648\n",
      "Validation results Epoch 11: Val loss - 0.1075, Test accuracy - 0.9702\n",
      "Saving model because its better\n",
      "---\n",
      "Началось обучение 12 эпохи\n",
      "The 12 Epoch of network learning is over:\n",
      "Train results Epoch 12: Train loss - 0.1123, Train accuracy - 0.9662\n",
      "Validation results Epoch 12: Val loss - 0.1021, Test accuracy - 0.9712\n",
      "Saving model because its better\n",
      "---\n",
      "Началось обучение 13 эпохи\n",
      "The 13 Epoch of network learning is over:\n",
      "Train results Epoch 13: Train loss - 0.1054, Train accuracy - 0.9686\n",
      "Validation results Epoch 13: Val loss - 0.1005, Test accuracy - 0.9702\n",
      "---\n",
      "Началось обучение 14 эпохи\n",
      "The 14 Epoch of network learning is over:\n",
      "Train results Epoch 14: Train loss - 0.0986, Train accuracy - 0.9707\n",
      "Validation results Epoch 14: Val loss - 0.0990, Test accuracy - 0.9714\n",
      "Saving model because its better\n",
      "---\n",
      "Началось обучение 15 эпохи\n",
      "The 15 Epoch of network learning is over:\n",
      "Train results Epoch 15: Train loss - 0.0945, Train accuracy - 0.9716\n",
      "Validation results Epoch 15: Val loss - 0.0970, Test accuracy - 0.9723\n",
      "Saving model because its better\n",
      "---\n",
      "max accuracy =  0.9723\n",
      "🏃 View run FCNetwork_1 at: http://localhost:5000/#/experiments/980200151464093923/runs/5315c1ddcc40415ba0c560d9b6850c45\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/980200151464093923\n"
     ]
    }
   ],
   "source": [
    "# Начало MLflow запуска\n",
    "with mlflow.start_run(run_name='FCNetwork_1') as run:\n",
    "    model = FCNetwork(prob=prob, n_inside=n_inside)\n",
    "    model.to(device)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    mlflow.log_param(\"prob dropout\", prob)\n",
    "    mlflow.log_param(\"neurons 2 layer\", n_inside)\n",
    "    mlflow.log_param(\"lr\", lr)\n",
    "    mlflow.log_param(\"optimizer\", 'Adam')\n",
    "    mlflow.log_param(\"epochs\", epochs)\n",
    "\n",
    "    maxacc = 0\n",
    "    itr_record = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch += 1\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        train_samples = 0\n",
    "\n",
    "        print(f'Началось обучение {epoch} эпохи')\n",
    "        for itr, data in enumerate(train_loader):\n",
    "            imgs = data[0].to(device)  # [B, H, W]\n",
    "            labels = data[1].to(device)\n",
    "\n",
    "            y_pred = model(imgs) \n",
    "            loss = loss_func(y_pred, labels)\n",
    "\n",
    "            train_loss += loss.item() * imgs.size(0)\n",
    "            train_acc += accuracy(y_pred, labels) * imgs.size(0)\n",
    "            train_samples += imgs.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss /= train_samples\n",
    "        train_acc /= train_samples\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_acc\", train_acc, step=epoch)\n",
    "        print(f'The {epoch} Epoch of network learning is over:')\n",
    "        print(f'Train results Epoch {epoch}: Train loss - {train_loss:.4f}, Train accuracy - {train_acc:.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        val_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for itr, data in enumerate(val_loader):\n",
    "                imgs = data[0].to(device)\n",
    "                labels = data[1].to(device)\n",
    "                y_pred = model(imgs)\n",
    "                loss = loss_func(y_pred, labels)\n",
    "\n",
    "                val_loss += loss.item() * imgs.size(0)\n",
    "                val_acc += accuracy(y_pred, labels) * imgs.size(0)\n",
    "                val_samples += imgs.size(0)\n",
    "\n",
    "        val_loss /= val_samples\n",
    "        val_acc /= val_samples\n",
    "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_acc\", val_acc, step=epoch)\n",
    "        print(f'Validation results Epoch {epoch}: Val loss - {val_loss:.4f}, Test accuracy - {val_acc:.4f}')\n",
    "\n",
    "        if val_acc > maxacc:\n",
    "            print('Saving model because its better')\n",
    "            maxacc = val_acc\n",
    "            mlflow.pytorch.log_model(model, \"model\")\n",
    "        print('---')\n",
    "\n",
    "    print('max accuracy = ', maxacc)\n",
    "    mlflow.log_metric(\"max val accuracy\", maxacc)\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
